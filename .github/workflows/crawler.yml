name: Baidu Hot News Crawler

on:
  schedule:
    - cron: "0,30 * * * *"  # 每半小时运行一次（UTC时间）
  workflow_dispatch:        # 允许手动触发
  push:
    branches: [ main ]     # main分支推送时触发测试

jobs:
  crawl:
    runs-on: ubuntu-22.04   # 使用LTS版本确保稳定性
    timeout-minutes: 30
    
    env:
      TZ: Asia/Shanghai     # 设置时区
      PYTHONUNBUFFERED: 1   # 实时Python输出
      MAX_RETRY: 3          # 重试次数

    steps:
      # 1. 检出代码（优化缓存）
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # 2. 设置Python环境
      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: 'pip'

      # 3. 安装系统依赖
      - name: Install system dependencies
        run: |
          sudo apt-get update -y
          sudo apt-get install -y \
            libnss3 libxss1 libasound2 libgbm1 \
            unzip curl gnupg ca-certificates \
            fonts-noto-cjk
          sudo apt-get clean

      # 4. 安装Python依赖
      - name: Install Python packages
        run: |
          python -m pip install --upgrade pip
          pip install --no-cache-dir -r requirements.txt

      # 5. Edge浏览器与WebDriver安装（关键改进）
      - name: Install Edge and WebDriver
        timeout-minutes: 10
        run: |
          # 安装Edge浏览器（带重试）
          for i in $(seq 1 $MAX_RETRY); do
            echo "Attempt $i/$MAX_RETRY: Installing Edge..."
            curl -fsSL https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor | sudo tee /usr/share/keyrings/microsoft-edge.gpg >/dev/null &&
            echo "deb [arch=amd64 signed-by=/usr/share/keyrings/microsoft-edge.gpg] https://packages.microsoft.com/repos/edge stable main" | sudo tee /etc/apt/sources.list.d/microsoft-edge.list &&
            sudo apt-get update -y &&
            sudo apt-get install -y microsoft-edge-stable && break || sleep 30
          done

          # 获取精确版本号（4段式）
          EDGE_FULL_VERSION=$(microsoft-edge --version | awk '{print $3}')
          echo "EDGE_VERSION=${EDGE_FULL_VERSION%.*}" >> $GITHUB_ENV
          echo "Installed Edge: $EDGE_FULL_VERSION"

          # WebDriver下载（多源回退）
          for VERSION in "${EDGE_FULL_VERSION%.*}" "${EDGE_FULL_VERSION%.*.*}"; do
            echo "Trying WebDriver v$VERSION..."
            if wget -q --tries=3 "https://msedgedriver.azureedge.net/$VERSION/edgedriver_linux64.zip" -O edgedriver.zip; then
              echo "Download succeeded with version $VERSION"
              break
            fi
          done

          # 解压验证
          unzip -q edgedriver.zip -d /usr/local/bin
          chmod +x /usr/local/bin/msedgedriver
          rm edgedriver.zip

          # 版本一致性检查
          if ! msedgedriver --version | grep -q "${EDGE_FULL_VERSION%.*}"; then
            echo "::error::Version mismatch! Edge: $EDGE_FULL_VERSION | Driver: $(msedgedriver --version)"
            exit 1
          fi

      # 6. 运行爬虫（增强监控）
      - name: Run crawler with monitoring
        env:
          MONGO_URI: ${{ secrets.MONGO_URI }}
          HEADLESS: "true"
        run: |
          START_TIME=$(date +%s)
          
          # 带超时运行
          timeout 25m python news_crawler.py 2>&1 | tee crawler.log
          
          # 错误分析
          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -eq 124 ]; then
            echo "::error::Crawler timed out after 25 minutes"
            exit 1
          elif [ $EXIT_CODE -ne 0 ]; then
            echo "::group::Last 50 lines of log"
            tail -n 50 crawler.log
            echo "::endgroup::"
            exit $EXIT_CODE
          fi
          
          # 性能报告
          echo "::notice::Execution time: $(($(date +%s)-$START_TIME))s"

      # 7. 上传产物（优化命名）
      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: artifacts-${{ github.run_id }}-${{ github.run_attempt }}
          path: |
            crawler.log
            !*.tmp
          retention-days: 7
          compression-level: 9

      # 8. 状态通知（可选）
      - name: Notify status
        if: always()
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const log = fs.existsSync('crawler.log') ? 
              fs.readFileSync('crawler.log', 'utf8').slice(-500) : 'No log';
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `Job ${context.job} ${process.env.GITHUB_JOB_STATUS}\nLog:\n\`\`\`\n${log}\n\`\`\``
            });
