# name: Baidu Hot News Crawler

# on:
#   schedule:
#     - cron: "0 */6 * * *"
#   workflow_dispatch:
#   push:
#     branches: [ main ]

# jobs:
#   crawl:
#     runs-on: ubuntu-22.04
#     timeout-minutes: 30

#     env:
#       TZ: Asia/Shanghai
#       PYTHONUNBUFFERED: 1
#       MAX_RETRY: 3
#       EDGE_DRIVER_URL: "https://msedgedriver.azureedge.net"

#     steps:
#       - name: Checkout code
#         uses: actions/checkout@v4
#         with:
#           fetch-depth: 0
#           persist-credentials: false

#       - name: Set up Python 3.10
#         uses: actions/setup-python@v4
#         with:
#           python-version: "3.10"
#           cache: 'pip'
#           cache-dependency-path: 'requirements.txt'

#       - name: Install system dependencies
#         run: |
#           sudo apt-get update -y
#           sudo apt-get install -y \
#             libnss3 libxss1 libasound2 libgbm1 \
#             unzip curl gnupg ca-certificates \
#             fonts-noto-cjk fonts-wqy-microhei
#           sudo apt-get clean
#           sudo rm -rf /var/lib/apt/lists/*

#       - name: Install Python packages
#         run: |
#           python -m pip install --upgrade pip
#           pip install --no-cache-dir -r requirements.txt
#           pip list

#       - name: Cache Edge WebDriver
#         id: cache-edgedriver
#         uses: actions/cache@v3
#         with:
#           path: edgedriver_cache/
#           key: edgedriver-${{ runner.os }}-${{ hashFiles('requirements.txt') }}
#           restore-keys: |
#             edgedriver-${{ runner.os }}-

#       - name: Check cache hit
#         run: |
#           echo "Cache hit: ${{ steps.cache-edgedriver.outputs.cache-hit }}"
#           if [[ '${{ steps.cache-edgedriver.outputs.cache-hit }}' == 'true' ]]; then
#             echo "Using cached WebDriver"
#           else
#             echo "No cache found, will download"
#           fi

#       - name: Install Edge and WebDriver
#         timeout-minutes: 10
#         run: |
#           # 安装 Edge 浏览器
#           echo "=== Installing Microsoft Edge ==="
#           curl -fsSL https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor | sudo tee /usr/share/keyrings/microsoft-edge.gpg >/dev/null
#           echo "deb [arch=amd64 signed-by=/usr/share/keyrings/microsoft-edge.gpg] https://packages.microsoft.com/repos/edge stable main" | sudo tee /etc/apt/sources.list.d/microsoft-edge.list
#           sudo apt-get update -y
#           sudo apt-get install -y microsoft-edge-stable

#           EDGE_FULL_VERSION=$(microsoft-edge --version | awk '{print $3}')
#           echo "EDGE_VERSION=${EDGE_FULL_VERSION%.*}" >> $GITHUB_ENV
#           echo "Installed Edge version: $EDGE_FULL_VERSION"

#           # 检查缓存是否有效
#           mkdir -p edgedriver_cache
#           DRIVER_BIN="edgedriver_cache/msedgedriver"
          
#           if [[ -f "$DRIVER_BIN" && "$($DRIVER_BIN --version | awk '{print $2}')" =~ ^${EDGE_FULL_VERSION%.*} ]]; then
#             echo "Using valid cached WebDriver."
#             sudo cp "$DRIVER_BIN" /usr/local/bin/msedgedriver
#             sudo chmod +x /usr/local/bin/msedgedriver
#             exit 0
#           fi

#           # 下载 WebDriver
#           echo "Downloading WebDriver..."
#           VERSION_PATTERNS=(
#             "$EDGE_FULL_VERSION"
#             "${EDGE_FULL_VERSION%.*}"
#             "${EDGE_FULL_VERSION%.*.*}"
#           )
          
#           for VERSION in "${VERSION_PATTERNS[@]}"; do
#             echo "Trying WebDriver version: $VERSION"
#             if wget -q --tries=3 --timeout=30 "$EDGE_DRIVER_URL/$VERSION/edgedriver_linux64.zip" -O "edgedriver_linux64.zip"; then
#               if unzip -tq "edgedriver_linux64.zip" >/dev/null 2>&1; then
#                 unzip -q -o "edgedriver_linux64.zip" -d edgedriver_cache
#                 sudo cp edgedriver_cache/msedgedriver /usr/local/bin/
#                 sudo chmod +x /usr/local/bin/msedgedriver
#                 break
#               else
#                 echo "Corrupted zip, retrying..."
#                 rm -f "edgedriver_linux64.zip"
#               fi
#             fi
#           done

#           if ! command -v msedgedriver >/dev/null; then
#             echo "::error::WebDriver installation failed"
#             exit 1
#           fi

#           # 验证版本
#           DRIVER_VERSION=$(msedgedriver --version | awk '{print $2}')
#           echo "WebDriver version: $DRIVER_VERSION"
#           if [[ ! "$DRIVER_VERSION" =~ ^${EDGE_FULL_VERSION%.*} ]]; then
#             echo "::warning::Version mismatch! Edge: $EDGE_FULL_VERSION | Driver: $DRIVER_VERSION"
#           fi

#       - name: Run crawler with monitoring
#         env:
#           MONGO_URI: ${{ secrets.MONGO_URI }}
#           HEADLESS: "true"
#           PYTHONPATH: "${{ github.workspace }}"
#         run: |
#           mkdir -p logs
#           LOG_FILE="logs/crawler_$(date +'%Y%m%d_%H%M%S').log"
#           START_TIME=$(date +%s)
#           timeout 25m python -u news_crawler.py 2>&1 | tee $LOG_FILE
#           EXIT_CODE=${PIPESTATUS[0]}
#           END_TIME=$(date +%s)
#           DURATION=$((END_TIME - START_TIME))

#           echo "=== Crawler Finished ==="
#           echo "Exit code: $EXIT_CODE"
#           echo "Duration: ${DURATION}s"

#           if [ $EXIT_CODE -eq 124 ]; then
#             echo "::error::Crawler timed out after 25 minutes"
#             exit 1
#           elif [ $EXIT_CODE -ne 0 ]; then
#             echo "::group::Error Details (last 100 lines)"
#             tail -n 100 $LOG_FILE
#             echo "::endgroup::"
#             echo "::error::Crawler failed with exit code $EXIT_CODE"
#             exit $EXIT_CODE
#           fi

#           echo "::notice::Crawler completed successfully in ${DURATION}s"
#           echo "duration=$DURATION" >> $GITHUB_OUTPUT

#       - name: Upload artifacts
#         if: always()
#         uses: actions/upload-artifact@v4
#         with:
#           name: crawler-artifacts-${{ github.run_id }}-${{ github.run_attempt }}
#           path: |
#             logs/
#             !*.tmp
#           retention-days: 7
#           compression-level: 9

#       - name: Notify Slack on failure
#         if: failure()
#         uses: slackapi/slack-github-action@v1.24.0
#         with:
#           payload: |
#             {
#               "text": "百度热榜爬虫运行失败",
#               "blocks": [
#                 {
#                   "type": "section",
#                   "text": {
#                     "type": "mrkdwn",
#                     "text": ":x: *百度热榜爬虫运行失败* \n*工作流*: ${{ github.workflow }} \n*运行ID*: ${{ github.run_id }} \n*分支*: ${{ github.ref }}"
#                   }
#                 },
#                 {
#                   "type": "section",
#                   "text": {
#                     "type": "mrkdwn",
#                     "text": "查看详情: <https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}|GitHub Actions>"
#                   }
#                 }
#               ]
#             }
#         env:
#           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}




# name: Baidu Hot News Crawler

# on:
#   schedule:
#     - cron: "0 */6 * * *"
#   workflow_dispatch:
#   push:
#     branches: [ main ]

# jobs:
#   crawl:
#     runs-on: ubuntu-22.04
#     timeout-minutes: 30

#     env:
#       TZ: Asia/Shanghai
#       PYTHONUNBUFFERED: 1
#       MAX_RETRY: 3
#       EDGE_DRIVER_URL: "https://msedgedriver.azureedge.net"

#     steps:
#       - name: Checkout code
#         uses: actions/checkout@v4
#         with:
#           fetch-depth: 0
#           persist-credentials: false

#       - name: Set up Python 3.10
#         uses: actions/setup-python@v4
#         with:
#           python-version: "3.10"
#           cache: 'pip'
#           cache-dependency-path: 'requirements.txt'

#       - name: Install system dependencies
#         run: |
#           sudo apt-get update -y
#           sudo apt-get install -y \
#             libnss3 libxss1 libasound2 libgbm1 \
#             unzip curl gnupg ca-certificates \
#             fonts-noto-cjk fonts-wqy-microhei
#           sudo apt-get clean
#           sudo rm -rf /var/lib/apt/lists/*

#       - name: Install Python packages
#         run: |
#           python -m pip install --upgrade pip
#           pip install --no-cache-dir -r requirements.txt
#           pip list

#       - name: Cache Edge WebDriver
#         id: cache-edgedriver
#         uses: actions/cache@v3
#         with:
#           path: edgedriver_cache/
#           key: edgedriver-${{ runner.os }}-${{ hashFiles('requirements.txt') }}
#           restore-keys: |
#             edgedriver-${{ runner.os }}-

#       - name: Check cache hit
#         run: |
#           echo "Cache hit: ${{ steps.cache-edgedriver.outputs.cache-hit }}"
#           if [[ '${{ steps.cache-edgedriver.outputs.cache-hit }}' == 'true' ]]; then
#             echo "Using cached WebDriver"
#           else
#             echo "No cache found, will download"
#           fi

#       - name: Install Edge and WebDriver
#         timeout-minutes: 10
#         run: |
#           # 安装 Edge 浏览器
#           echo "=== Installing Microsoft Edge ==="
#           curl -fsSL https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor | sudo tee /usr/share/keyrings/microsoft-edge.gpg >/dev/null
#           echo "deb [arch=amd64 signed-by=/usr/share/keyrings/microsoft-edge.gpg] https://packages.microsoft.com/repos/edge stable main" | sudo tee /etc/apt/sources.list.d/microsoft-edge.list
#           sudo apt-get update -y
#           sudo apt-get install -y microsoft-edge-stable

#           # 获取浏览器版本信息
#           echo "=== Browser Version Info ==="
#           EDGE_FULL_VERSION=$(microsoft-edge --version | awk '{print $3}')
#           EDGE_MAJOR_VERSION=${EDGE_FULL_VERSION%.*}
#           echo "EDGE_VERSION=$EDGE_MAJOR_VERSION" >> $GITHUB_ENV
#           echo "Installed Edge version: $EDGE_FULL_VERSION"
#           echo "Major version: $EDGE_MAJOR_VERSION"

#           # 检查缓存是否有效
#           mkdir -p edgedriver_cache
#           DRIVER_BIN="edgedriver_cache/msedgedriver"
          
#           if [[ -f "$DRIVER_BIN" ]]; then
#             CACHED_DRIVER_VERSION=$($DRIVER_BIN --version | awk '{print $2}')
#             echo "Cached WebDriver version: $CACHED_DRIVER_VERSION"
            
#             if [[ "$CACHED_DRIVER_VERSION" =~ ^$EDGE_MAJOR_VERSION ]]; then
#               echo "Using valid cached WebDriver (version matches)"
#               sudo cp "$DRIVER_BIN" /usr/local/bin/msedgedriver
#               sudo chmod +x /usr/local/bin/msedgedriver
#               exit 0
#             else
#               echo "Cached WebDriver version mismatch (Edge: $EDGE_MAJOR_VERSION, Driver: $CACHED_DRIVER_VERSION)"
#               rm -f "$DRIVER_BIN"
#             fi
#           fi

#           # 下载 WebDriver
#           echo "=== Downloading WebDriver ==="
#           VERSION_PATTERNS=(
#             "$EDGE_FULL_VERSION"
#             "$EDGE_MAJOR_VERSION"
#             "${EDGE_MAJOR_VERSION%.*}"
#           )
          
#           for VERSION in "${VERSION_PATTERNS[@]}"; do
#             echo "Trying WebDriver version: $VERSION"
#             if wget -q --tries=3 --timeout=30 "$EDGE_DRIVER_URL/$VERSION/edgedriver_linux64.zip" -O "edgedriver_linux64.zip"; then
#               if unzip -tq "edgedriver_linux64.zip" >/dev/null 2>&1; then
#                 unzip -q -o "edgedriver_linux64.zip" -d edgedriver_cache
#                 sudo cp edgedriver_cache/msedgedriver /usr/local/bin/
#                 sudo chmod +x /usr/local/bin/msedgedriver
#                 break
#               else
#                 echo "Corrupted zip, retrying..."
#                 rm -f "edgedriver_linux64.zip"
#               fi
#             fi
#           done

#           # 验证安装结果
#           echo "=== Verification ==="
#           if ! command -v msedgedriver >/dev/null; then
#             echo "::error::WebDriver installation failed"
#             exit 1
#           fi

#           DRIVER_VERSION=$(msedgedriver --version | awk '{print $2}')
#           echo "Installed WebDriver version: $DRIVER_VERSION"
          
#           if [[ ! "$DRIVER_VERSION" =~ ^$EDGE_MAJOR_VERSION ]]; then
#             echo "::warning::Version mismatch! Edge: $EDGE_MAJOR_VERSION | Driver: $DRIVER_VERSION"
#           else
#             echo "Version match confirmed"
#           fi

#           # 输出环境信息
#           echo "=== Environment Info ==="
#           echo "PATH: $PATH"
#           echo "WebDriver path: $(which msedgedriver)"
#           ls -la $(which msedgedriver)

#       - name: Verify Edge Environment
#         run: |
#           echo "=== Final Verification ==="
#           echo "Browser version: $(microsoft-edge --version)"
#           echo "Driver version: $(msedgedriver --version)"
#           echo "Driver location: $(which msedgedriver)"
#           echo "Driver permissions: $(ls -la $(which msedgedriver))"
#           echo "Driver test:"
#           msedgedriver --version || echo "Driver test failed"

#       - name: Run crawler with monitoring
#         env:
#           MONGO_URI: ${{ secrets.MONGO_URI }}
#           HEADLESS: "true"
#           PYTHONPATH: "${{ github.workspace }}"
#         run: |
#           mkdir -p logs
#           LOG_FILE="logs/crawler_$(date +'%Y%m%d_%H%M%S').log"
#           START_TIME=$(date +%s)
#           timeout 25m python -u news_crawler.py 2>&1 | tee $LOG_FILE
#           EXIT_CODE=${PIPESTATUS[0]}
#           END_TIME=$(date +%s)
#           DURATION=$((END_TIME - START_TIME))

#           echo "=== Crawler Finished ==="
#           echo "Exit code: $EXIT_CODE"
#           echo "Duration: ${DURATION}s"

#           if [ $EXIT_CODE -eq 124 ]; then
#             echo "::error::Crawler timed out after 25 minutes"
#             exit 1
#           elif [ $EXIT_CODE -ne 0 ]; then
#             echo "::group::Error Details (last 100 lines)"
#             tail -n 100 $LOG_FILE
#             echo "::endgroup::"
#             echo "::error::Crawler failed with exit code $EXIT_CODE"
#             exit $EXIT_CODE
#           fi

#           echo "::notice::Crawler completed successfully in ${DURATION}s"
#           echo "duration=$DURATION" >> $GITHUB_OUTPUT

#       - name: Upload artifacts
#         if: always()
#         uses: actions/upload-artifact@v4
#         with:
#           name: crawler-artifacts-${{ github.run_id }}-${{ github.run_attempt }}
#           path: |
#             logs/
#             !*.tmp
#           retention-days: 7
#           compression-level: 9

#       - name: Notify Slack on failure
#         if: failure()
#         uses: slackapi/slack-github-action@v1.24.0
#         with:
#           payload: |
#             {
#               "text": "百度热榜爬虫运行失败",
#               "blocks": [
#                 {
#                   "type": "section",
#                   "text": {
#                     "type": "mrkdwn",
#                     "text": ":x: *百度热榜爬虫运行失败* \n*工作流*: ${{ github.workflow }} \n*运行ID*: ${{ github.run_id }} \n*分支*: ${{ github.ref }}"
#                   }
#                 },
#                 {
#                   "type": "section",
#                   "text": {
#                     "type": "mrkdwn",
#                     "text": "查看详情: <https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}|GitHub Actions>"
#                   }
#                 }
#               ]
#             }
#         env:
#           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}


name: Baidu Hot News Crawler

on:
  schedule:
    - cron: "0 */6 * * *"  # 每 6 小时运行一次
  workflow_dispatch:
  push:
    branches: [ main ]

jobs:
  crawl:
    runs-on: ubuntu-22.04
    timeout-minutes: 30

    env:
      TZ: Asia/Shanghai
      PYTHONUNBUFFERED: 1
      MAX_RETRY: 3

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: false

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'

      - name: Install system dependencies
        run: |
          sudo apt-get update -y
          sudo apt-get install -y \
            libnss3 libxss1 libasound2 libgbm1 \
            unzip curl gnupg ca-certificates \
            fonts-noto-cjk fonts-wqy-microhei
          sudo apt-get clean
          sudo rm -rf /var/lib/apt/lists/*

      - name: Install Python packages
        run: |
          python -m pip install --upgrade pip
          pip install --no-cache-dir -r requirements.txt
          pip list

      - name: Install Microsoft Edge
        run: |
          curl -fsSL https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor | sudo tee /usr/share/keyrings/microsoft-edge.gpg >/dev/null
          echo "deb [arch=amd64 signed-by=/usr/share/keyrings/microsoft-edge.gpg] https://packages.microsoft.com/repos/edge stable main" | sudo tee /etc/apt/sources.list.d/microsoft-edge.list
          sudo apt-get update -y
          sudo apt-get install -y microsoft-edge-stable

      - name: Use WebDriver from drivers/
        run: |
          echo "Copying msedgedriver from repository"
          chmod +x drivers/msedgedriver
          sudo cp drivers/msedgedriver /usr/local/bin/msedgedriver
          sudo chmod +x /usr/local/bin/msedgedriver
          echo "Driver path: $(which msedgedriver)"
          msedgedriver --version

      - name: Verify Edge Environment
        run: |
          echo "Browser version: $(microsoft-edge --version)"
          echo "Driver version: $(msedgedriver --version)"
          echo "Driver path: $(which msedgedriver)"
          echo "Driver permissions: $(ls -la $(which msedgedriver))"

      - name: Run crawler with monitoring
        env:
          MONGO_URI: ${{ secrets.MONGO_URI }}
          HEADLESS: "true"
          PYTHONPATH: "${{ github.workspace }}"
        run: |
          mkdir -p logs
          LOG_FILE="logs/crawler_$(date +'%Y%m%d_%H%M%S').log"
          START_TIME=$(date +%s)
          timeout 25m python -u news_crawler.py 2>&1 | tee $LOG_FILE
          EXIT_CODE=${PIPESTATUS[0]}
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))

          echo "=== Crawler Finished ==="
          echo "Exit code: $EXIT_CODE"
          echo "Duration: ${DURATION}s"

          if [ $EXIT_CODE -eq 124 ]; then
            echo "::error::Crawler timed out after 25 minutes"
            exit 1
          elif [ $EXIT_CODE -ne 0 ]; then
            echo "::group::Error Details (last 100 lines)"
            tail -n 100 $LOG_FILE
            echo "::endgroup::"
            echo "::error::Crawler failed with exit code $EXIT_CODE"
            exit $EXIT_CODE
          fi

          echo "::notice::Crawler completed successfully in ${DURATION}s"
          echo "duration=$DURATION" >> $GITHUB_OUTPUT

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: crawler-artifacts-${{ github.run_id }}-${{ github.run_attempt }}
          path: |
            logs/
            !*.tmp
          retention-days: 7
          compression-level: 9

      - name: Notify Slack on failure
        if: failure()
        uses: slackapi/slack-github-action@v1.24.0
        with:
          payload: |
            {
              "text": "百度热榜爬虫运行失败",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": ":x: *百度热榜爬虫运行失败* \n*工作流*: ${{ github.workflow }} \n*运行ID*: ${{ github.run_id }} \n*分支*: ${{ github.ref }}"
                  }
                },
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "查看详情: <https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}|GitHub Actions>"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}


